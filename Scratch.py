import os
import requests
import re
from datetime import datetime
from issue_classifier import classify_issue_with_confidence

# --- 1. é…ç½®åŒºåŸŸ ---
GITHUB_TOKEN = os.getenv('GITHUB_TOKEN', 'YOUR_PERSONAL_ACCESS_TOKEN') 
REPO_OWNER = 'Microsoft'
REPO_NAME = 'vscode'
SINCE_DATE = '2025-09-01'
BASE_OUTPUT_DIR = 'github_issues_output'

# --- è„šæœ¬ä¸»è¦é€»è¾‘ ---

def get_existing_issue_map(directory):
    if not os.path.exists(directory):
        return {}
    
    issue_map = {}
    id_pattern = re.compile(r'issue_(\d+)_.*\.md')
    
    for root, _, files in os.walk(directory):
        for filename in files:
            match = id_pattern.match(filename)
            if match:
                issue_id = match.group(1)
                issue_map[issue_id] = os.path.join(root, filename)
            
    return issue_map

def fetch_and_process_issues(existing_issue_map):
    all_issues = []
    # å…ˆè·å– openï¼Œå†è·å– closed
    for state in ['open']: # , 'closed'
        print(f"--- å¼€å§‹è·å– '{state}' çŠ¶æ€çš„ Issues ---")
        api_url = f'https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/issues'
        headers = {
            'Authorization': f'token {GITHUB_TOKEN}',
            'Accept': 'application/vnd.github.v3+json'
        }
        params = {
            'state': state,
            'since': SINCE_DATE,
            'direction': 'desc',
            'sort': 'updated', # æŒ‰æ›´æ–°æ—¶é—´æ’åºï¼Œæ›´å®¹æ˜“æ•è·çŠ¶æ€å˜åŒ–
            'per_page': 100
        }
        page = 1
        
        while api_url:
            print(f"æ­£åœ¨è·å– '{state}' Issues, ç¬¬ {page} é¡µ...")
            try:
                response = requests.get(api_url, headers=headers, params=params)
                response.raise_for_status()
            except requests.exceptions.RequestException as err:
                print(f"ç½‘ç»œæˆ–APIè¯·æ±‚å¤±è´¥: {err}")
                break

            issues_page = response.json()
            if not issues_page:
                break
            
            all_issues.extend(issues_page)
            
            if 'next' in response.links:
                api_url = response.links['next']['url']
                params = {} 
            else:
                api_url = None
            page += 1

    print(f"\n--- è·å–å®Œæˆï¼Œå…± {len(all_issues)} æ¡ issuesã€‚å¼€å§‹å¤„ç†å’Œä¿å­˜... ---")
    
    # ç»Ÿä¸€å¤„ç†æ‰€æœ‰è·å–åˆ°çš„ issues
    new_count = 0
    skipped_count = 0
    for issue in all_issues:
        issue_id_str = str(issue['number'])

        # æ£€æŸ¥ issue æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è·³è¿‡
        if issue_id_str in existing_issue_map:
            print(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨çš„ Issue #{issue_id_str}")
            skipped_count += 1
            continue
        else:
            # å¦‚æœæ˜¯å…¨æ–°çš„ issueï¼Œç›´æ¥ä¿å­˜
            save_issue_as_markdown(issue)
            new_count += 1
            
    print(f"\n--- å¤„ç†å®Œæ¯• ---")
    print(f"æ–°å¢ Issue: {new_count} ä¸ª")
    print(f"è·³è¿‡å·²å­˜åœ¨ Issue: {skipped_count} ä¸ª")


def save_issue_as_markdown(issue):
    state_dir = 'open_issues' if issue['state'] == 'open' else 'closed_issues'

    # ä½¿ç”¨å¢å¼ºåˆ†ç±»å™¨
    title = issue.get('title', '')
    body = issue.get('body', '')
    labels = [label.get('name', '') for label in issue.get('labels', [])] if issue.get('labels') else []

    category, confidence = classify_issue_with_confidence(title, body, labels)
    category_dir = category

    # å¯é€‰ï¼šè¾“å‡ºåˆ†ç±»ä¿¡æ¯ç”¨äºè°ƒè¯•
    print(f"  ğŸ“Š Issue #{issue['number']} åˆ†ç±»ä¸º: {category_dir} (ç½®ä¿¡åº¦: {confidence:.2f})")
    
    output_dir = os.path.join(BASE_OUTPUT_DIR, state_dir, category_dir)
    os.makedirs(output_dir, exist_ok=True)
    
    safe_title = "".join(c for c in issue['title'] if c.isalnum() or c in (' ', '_', '-')).rstrip()
    filename = f"issue_{issue['number']}_{safe_title[:50]}.md"
    filepath = os.path.join(output_dir, filename)

    md_content = f"""# Issue #{issue['number']}: {issue['title']}
- **çŠ¶æ€ (State)**: {issue['state']}
- **åˆ›å»ºè€… (Author)**: [{issue['user']['login']}]({issue['user']['html_url']})
- **åˆ›å»ºæ—¶é—´ (Created at)**: {datetime.strptime(issue['created_at'], '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d %H:%M:%S')}
- **GitHub é“¾æ¥**: [View on GitHub]({issue['html_url']})
---
## æè¿° (Description)

{issue['body'] if issue['body'] else "æ­¤ Issue æ²¡æœ‰æä¾›æè¿°ã€‚"}
"""
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(md_content)
    except IOError as e:
        print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {filepath}. é”™è¯¯: {e}")

if __name__ == '__main__':
    if 'YOUR_PERSONAL_ACCESS_TOKEN' in GITHUB_TOKEN or not GITHUB_TOKEN:
        print("é”™è¯¯: è¯·åœ¨è„šæœ¬çš„é…ç½®åŒºåŸŸå¡«å…¥æ‚¨çš„ GitHub Personal Access Tokenï¼")
    else:
        # 1. å…ˆè·å–æœ¬åœ°æ‰€æœ‰å·²å­˜åœ¨çš„ issue
        existing_map = get_existing_issue_map(BASE_OUTPUT_DIR)
        print(f"æ‰«ææœ¬åœ°ï¼Œå‘ç° {len(existing_map)} ä¸ªå·²å­˜åœ¨çš„ issuesã€‚")
        # 2. è·å–å¹¶å¤„ç†
        fetch_and_process_issues(existing_map)
        print("\næ‰€æœ‰æ“ä½œå®Œæˆï¼")